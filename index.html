<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd"><html xmlns="http://www.w3.org/1999/xhtml">  <head>    <meta http-equiv="content-type" content="application/xhtml+xml; charset=UTF-8" />    <meta />    <meta />    <meta />    <meta />    <link rel="stylesheet" type="text/css" href="../../style/origo.css" media="all" />    <meta name="author" content="Lei Li" />    <title>MLDL</title>  </head>  <body>    <h1 align="center">291K Machine Learning (Fall 2022)<br />    </h1>    <h2>Course Description </h2>    <p> Machine Learning is about developing systems that automatically improve      their performance through experience. It has found massive applications in      real products. Examples include systems that recommend online videos,      automatic translating languages, and autonomous driving vehicles. This      advanced course gives a <b>general</b> and <b>in-depth</b> introduction      to the theory, models, and practical algorithms for machine learning.      Topics include learning problems (supervised learning, unsupervised      learning, self-supervised learning, reinforcement learning, and online      learning); modeling tools (graphical models, neural networks, kernel      methods, tree methods); as well as theoretical foundations (learning      theory, optimization). We focus on both the principles, analytical skills      and implementation practice. This course is suitable for graduate students      who want to pursue a career in AI/ML, to conduct research in this area, or      apply ML methods in their own projects. No prior knowledge of machine      learning is assumed. </p>    <h2>Instructor</h2>    <p><a href="https://www.cs.ucsb.edu/%7Eleili">Lei Li</a>  (Office Hour:      Tuesdays 4-5pm, book a slot <a href="https://calendar.app.google/fgG2YsU81vb6HNhg8">here</a>)    </p>    <p><a href="https://sites.cs.ucsb.edu/%7Eyuxiangw/">Yu-Xiang Wang</a>      (Office Hour: )</p>    <h2>Teaching Assistant</h2>    <ul>      <li>Xuandong Zhao (Office Hour: ) </li>    </ul>    <h2>Time and Location</h2>    <p>Tue/Thur 11am - 12:50pm (PHELP 3526)</p>    <h2>Textbook</h2>    <ul>      <li>[PRML] Pattern Recognition and Machine Learning, Chris Bishop.        available <a href="https://www.microsoft.com/en-us/research/uploads/prod/2006/01/Bishop-Pattern-Recognition-and-Machine-Learning-2006.pdf">online</a></li>      <li>[FML] Foundations of Machine Learning. Mehryar Mohri, Afshin        Rostamizadeh, and Ameet Talwalkar. available <a href="https://cs.nyu.edu/%7Emohri/mlbook/">online</a>.</li>    </ul>    The textbook below is a great resource for those hoping to brush up on the    prerequisite mathematics background for this course.    <ul>      <li>Mathematics for Machine Learning, Marc Peter Deisenroth, A. Aldo        Faisal, and Cheng Soon Ong. Free <a href="https://mml-book.github.io/">online</a>.<br />      </li>    </ul>    <h2>Prerequisites</h2>    Linear algebra (MATH 3B), Vector Calculus (6A), Probability and Statistics    (PSTAT 120A, 120B), algorithms (CS 130A &amp; 130B), and familiarity with    Python programming.    <h2>Homework Submission &amp; Grading</h2>    <ul>      <li>We use Gradescope to grade all homework. You will be automatically        added.  </li>      <ul>      </ul>    </ul>    <h2>Discussion Forum</h2>    <p>We will use Edstem platform. Please signup <a href="https://edstem.org/us/join/nPdFks">here</a></p>    <h2>Policy</h2>    <p>Please read the following <a href="course_policy.html">Link</a>      carefully!<br />    </p>    <h2>Syllabus</h2>    <table width="100%" border="0">      <tbody>        <tr>          <td>#<br />          </td>          <td>Date<br />          </td>          <td>Topic<br />          </td>          <td>Reading<br />          </td>          <td>Homework<br />          </td>        </tr>        <tr>          <td>1<br />          </td>          <td>9/22<br />          </td>          <td> Introduction, Supervised Learning<br />          </td>          <td><br />          </td>          <td><br />          </td>        </tr>        <tr>          <td>2<br />          </td>          <td>9/27<br />          </td>          <td>Classification, Logistic Regression, Decision Tree<br />          </td>          <td><br />          </td>          <td>HW1<br />          </td>        </tr>        <tr>          <td>3<br />          </td>          <td>9/29<br />          </td>          <td>Optimization basic: Gradient Descent<br />          </td>          <td><br />          </td>          <td><br />          </td>        </tr>        <tr>          <td>4<br />          </td>          <td>10/4<br />          </td>          <td>Unsupervised Learning, dimensionality reduction<br />          </td>          <td><br />          </td>          <td><br />          </td>        </tr>        <tr>          <td>5<br />          </td>          <td>10/6<br />          </td>          <td>Feedforward Neural Network, Backpropagation</td>          <td><br />          </td>          <td><br />          </td>        </tr>        <tr>          <td>6<br />          </td>          <td>10/11<br />          </td>          <td>Convolutional Neural Network, Residual Network</td>          <td><br />          </td>          <td>HW1 due, HW2<br />          </td>        </tr>        <tr>          <td>7<br />          </td>          <td>10/13<br />          </td>          <td><a href="12-recurrent_neural_net.pdf"> </a>Recurrent Neural            Networks, LSTM, Seq2seq </td>          <td><br />          </td>          <td><br />          </td>        </tr>        <tr>          <td>8<br />          </td>          <td>10/18<br />          </td>          <td>Transformer, BERT, GPT</td>          <td><br />          </td>          <td><br />          </td>        </tr>        <tr>          <td>9<br />          </td>          <td>10/20<br />          </td>          <td>Graphical Models intro</td>          <td><br />          </td>          <td><br />          </td>        </tr>        <tr>          <td>10<br />          </td>          <td>10/25<br />          </td>          <td> Bayesian Networks, Gaussian Mixture Models, EM</td>          <td><br />          </td>          <td><br />          </td>        </tr>        <tr>          <td>11<br />          </td>          <td>10/27<br />          </td>          <td> Undirected Graphical Models, Conditional Random Fields</td>          <td><br />          </td>          <td>HW2 due, HW3</td>        </tr>        <tr>          <td>12<br />          </td>          <td>11/1<br />          </td>          <td>Inference, VAE<br />          </td>          <td><br />          </td>          <td><br />          </td>        </tr>        <tr>          <td>13<br />          </td>          <td>11/3<br />          </td>          <td>Bayesian Inference, Metropolis-Hastings, Gibbs sampling<br />          </td>          <td><br />          </td>          <td><br />          </td>        </tr>        <tr>          <td>14<br />          </td>          <td>11/8<br />          </td>          <td> Convex Optimization<br />          </td>          <td><br />          </td>          <td><br />          </td>        </tr>        <tr>          <td>15<br />          </td>          <td>11/10<br />          </td>          <td> Support Vector Machine, Kernel Methods<br />          </td>          <td><br />          </td>          <td><br />          </td>        </tr>        <tr>          <td>16<br />          </td>          <td>11/15<br />          </td>          <td> Online Learning</td>          <td><br />          </td>          <td>HW3 due, HW4 out</td>        </tr>        <tr>          <td>17<br />          </td>          <td>11/17<br />          </td>          <td>Statistical Learning Theory<br />          </td>          <td><br />          </td>          <td><br />          </td>        </tr>        <tr>          <td>18<br />          </td>          <td>11/22<br />          </td>          <td>Markov Decision Process, Value Iteration</td>          <td><br />          </td>          <td><br />          </td>        </tr>        <tr>          <td>19<br />          </td>          <td>11/29<br />          </td>          <td> Reinforcement Learning algorithm, Q-learning</td>          <td><br />          </td>          <td><br />          </td>        </tr>        <tr>          <td>20<br />          </td>          <td>12/1<br />          </td>          <td> Reinforcement Learning algorithm 2, Exploration, Bandits. </td>          <td><br />          </td>          <td><br />          </td>        </tr>        <tr>          <td><br />          </td>          <td><br />          </td>          <td> Final project poster presentation </td>          <td><br />          </td>          <td>HW4 due<br />          </td>        </tr>      </tbody>    </table>    <p><br />    </p>  </body></html>